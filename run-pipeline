#!/usr/bin/perl
#SBATCH --cpus-per-task=64
#SBATCH --nodes=1
#SBATCH -p main,viz
#SBATCH --account=snap
#SBATCH --export=ALL,SLURMBATCH=yes
use strict;
use warnings;

=head1 NAME

run-pipeline - Execute all or part of the data-processing pipeline

=head1 SYNOPSIS

    run-pipeline [-h|--help] [-n|--dry-run] [-p|--procs PROCS]
        [-d|--dir DATA_DIR] [-e|--python EXEC] [--script-dir DIR]
        [-g|--groups DATA_GROUPS] [-s|--steps STEPS]
    run-pipeline ls

    Options:
        -h|--help:      Print help information and exit
        -n|--dry-run:   Show which steps of the pipeline will get run
                        but don't actually run them.
        -e|--python     Override the path the to the python executable.
                        You'll want this if using SLURM so the code
                        still runs in your virtual environment.
        -p|--procs:     Maximum number of parallel processes to run. Not
                        all steps in the pipeline use this.
        -d|--dir:       Specify the directory where the data for the
                        pipeline lies. Defaults to:
                        '/workspace/Shared/Tech_Projects/DOT/project_data/wrf_pcpt/'
        --script-dir:   Specify the directory where the python scripts
                        for the pipeline steps lie. Defaults to './pipeline'
                        relative to the directory that this script is in.
                        The SLURM sbatch command makes a copy of the script
                        and puts it somewhere else, so you'll need to use this
                        if running through SLURM.
        -g|--groups:    Specify which data groups to run.
                        Defaults to: 'all'
        -s|--steps:     Specify which steps to run.
                        Defaults to: 'all'

DATA_GROUPS is a comma-separated list of the data groups/models to execute
the pipeline for. The elements of the list can be any of the following values:

    NCAR-CCSM4_historical
    NCAR-CCSM4_rcp85
    ERA-Interim_historical
    GFDL-CM3_historical
    GFDL-CM3_rcp85

Alternatively, this argument can simply be the string "all" to execute 
for all groups. Technically, the values given here are treated as regular
expressions, so you can sepcify substrings like 'historical' or 'GFDL-CM3'
to match multiple groups.
Some steps in the pipeline may require specific data groups
or combinations of them. For example, the 'deltas' step and beyond requires
that both the 'rcp85' and 'historical' models for GFDL-CM3 or NCAR-CCSM4
be included.

STEPS is a comma-separated list of steps to run in the pipeline. The format
is analgous to the field selection of the cut(1) command. Each element of the
list can be either the name of a step, or a range in one of the formats
below:

    NAME        The single step with NAME
    NAME-       The step with NAME and every step after it
    NAME-NAME2  All the steps from NAME to NAME2 (inclusive)
    -NAME       The steps from the first one up through NAME

Every step will only be run once and always in the order that the script
defines for the pipeline, REGARDLESS of how you specify them in the list.
Like with DATA_GROUPS, this can also be the string "all" to execute all steps.

Execute `run-pipeline ls` to see a list of the names for all the steps in
the pipeline and a description of each step, as well as a list of all 
possible data group names.

=cut

#######################
# Global data and flags
#######################

use File::Basename;
use File::Spec qw(rel2abs);

# Ordering of steps
my @order = qw(durations ams intervals deltas warp multiply);

# Mapping of steps to descriptions
my %descriptions = (
    'durations' => "Compute durations series from raw hourly data",
    'ams'       => "Compute annual maximum series form durations series",
    'intervals' => "Compute return intervals (with confidence bounds) from annual maximum series",
    'deltas'    => "Compute ratios of differences between historical and projected data groups",
    'warp'      => "Warp grids of deltas to match grid of NOAA Atlas 14 data",
    'multiply'  => "Multiply by NOAA Atlas 14 data by deltas for final product."
);

# Mapping indicating whether each step should be performed.
# (Defaults to true for all)
my %do_steps = map { $_ => 1 } @order;

# List of possible data set names
my @allowed_data_groups = qw(
    NCAR-CCSM4_historical
    NCAR-CCSM4_rcp85
    ERA-Interim_historical
    GFDL-CM3_historical
    GFDL-CM3_rcp85
);

# Mapping indicating whether each data group is used
# (Defaults to true for all)
my %use_group = map { $_ => 1} @allowed_data_groups;

# Default arguments/flags
my $dry_run     = 0;
my $python_exec = 'python3';
my $in_slurm    = defined $ENV{'SLURMBATCH'};
my $max_procs   = 5;
my $data_dir    = '/workspace/Shared/Tech_Projects/DOT/project_data/wrf_pcpt/';
my $script_dir  = dirname($0) . "/pipeline";

#######################
# MAIN
#######################

# Print list of steps and data groups if 'ls' is the
# first (and only) argument
if (@ARGV == 1 && $ARGV[0] eq 'ls') {
    print "The steps of the pipeline are (in order):\n";
    foreach (0..$#order) {
        printf "\t\033[1m%d: %-10s\033[0m\t%s\n", $_+1, $order[$_], $descriptions{$order[$_]};
    }
    print "The allowed data groups are:\n";
    foreach (@allowed_data_groups) {
        print "\033[1m\t$_\033[0m\n";
    }
    exit 0;
}

use Getopt::Long qw(GetOptions Configure);
use Pod::Usage qw(pod2usage);

# Parse Options
Configure qw'auto_help';
GetOptions(
    'dry-run|n'     => \$dry_run,
    'procs|p=i'     => \$max_procs,
    'python|e=s'    => \$python_exec,
    'dir|d=s'       => \$data_dir,
    'script-dir=s'  => \$script_dir,
    'groups|g=s'    => \&parse_data_groups,
    'steps|s=s'     => \&parse_steps
) or die "Invalid options!";

# There should be no other arguments after parsing options
pod2usage("Invalid arguments.") if (@ARGV);

# Confirm that data directory exists.
die "Data directory, $data_dir, is not a directory." unless ($dry_run || -d $data_dir);

#######################
# STAGE 1
#######################

# Stage 1 consists of the steps from durations through intervals.
# It is repeated for each of the five data groups.

for my $group (grep $use_group{$_}, @allowed_data_groups) {
    print "\033[1m>>> $group <<<\033[0m\n";

    #
    # Durations
    #
    if ($do_steps{'durations'}) {
        print "Step: \033[1mDurations\033[0m...\n";
        unless ($dry_run) {
            check_input_dir("pcpt");
            create_output_dir("durations");
        }

        my @command = (
            "$python_exec", "$script_dir/make_durations_series_wrf_data.py",
            '-p', "$data_dir/pcpt/",
            '-o', "$data_dir/durations/",
            '-d', "$group"
        );
        unshift(@command, 'srun') if ($in_slurm);

        do_command(@command)
    }

    #
    # AMS
    #
    if ($do_steps{'ams'}) {
        print "Step: \033[1mAMS\033[0m...\n";
        unless ($dry_run) {
            check_input_dir("durations");
            create_output_dir("annual_maximum_series");
        }

        my @command = (
            "$python_exec", "$script_dir/make_annual_maximum_series_wrf_data.py",
            '-p', "$data_dir/durations/", 
            '-o', "$data_dir/annual_maximum_series/",
            '-d', "$group"
        );
        unshift(@command, 'srun') if ($in_slurm);

        do_command(@command);
    }

    #
    # Intervals
    #
    if ($do_steps{'intervals'}) {
        print "Step: \033[1mIntervals\033[0m...\n";
        # The intervals step works a little differently than most of the other
        # steps in that it must be called separately for each input file whereas
        # the other commands simply take the input directory as an argument
        # and iterate through each file within the python code.

        unless ($dry_run) {
            check_input_dir("annual_maximum_series");
            create_output_dir("output_interval_durations");
        }

        my @command = (
            "$python_exec", "$script_dir/compute_return_intervals_with_confbounds.py",
            '-o', "$data_dir/output_interval_durations", '-n', "$max_procs", '-fn'
        );
        unshift(@command, 'srun', '-c', "$max_procs") if ($in_slurm);

        # This step requires being able to read the files in the input directory,
        # but since the dry run doesn't guarantee its existence, we can't read
        # it when doing the dry run. So instead, we print an equivalent
        # shell command that will read the directory and execute the script
        # for each file.
        if ($dry_run) {
            print "\033[3;36mfor FILE in $data_dir/annual_maximum_series/*$group*.nc ; do\n\t@command \$FILE\ndone\033[0m\n";
        } 
        # If not a dry run, we get a list of the files in the input directory
        # and execute the script for each one.
        else {
            my $input_data = "$data_dir/annual_maximum_series";
            opendir(my $dh, $input_data) || die "Can't open directory: $input_data: $!";
            my @input_files = grep {-f "$input_data/$_" && /.*\Q$group\E.*\.nc/} readdir($dh);
            do { print " $_\n"; do_command(@command, "$input_data/$_") } for (@input_files);
        }
    }
} # end FOR $group

# If no steps after 'intervals' are being performed, we can stop now.
exit 0 unless (grep $do_steps{$_}, @order[get_order('deltas')..$#order]);

#######################
# STAGE 2
#######################

#
# The steps from this point forward act on pairs of historical and 
# projected (rcp85) models, so for either the NCAR-CCSM4 or GFDL-CM3 models,
# both the historical and rcp85 versions need to have been included.
#

# Print warnings to the user if any specified groups cannot be used.
if ($use_group{'ERA-Interim_historical'}) {
    print STDERR "\033[33;1mWARNING:\033[0m ERA-Interim_historical is not used".
        " for the remaining steps, so it will be ignored.\n"
}
if ($use_group{'NCAR-CCSM4_historical'} xor $use_group{'NCAR-CCSM4_rcp85'}) {
    print STDERR "\033[33;1mWARNING:\033[0m Both the historical and projected".
        " (rcp85) versions of the NCAR-CCSM4 model must be specified.".
        " But only one was specified, so it will be ignored.\n"
}
if ($use_group{'GFDL-CM3_historical'} xor $use_group{'GFDL-CM3_rcp85'}) {
    print STDERR "\033[33;1mWARNING:\033[0m Both the historical and projected".
        " (rcp85) versions of the GFDL-CM3 model must be specified.".
        " But only one was specified, so it will be ignored.\n"
}

# Get which pairs of models were specified
my %pairs = (
    'NCAR-CCSM4' => 
        $use_group{'NCAR-CCSM4_historical'} && $use_group{'NCAR-CCSM4_rcp85'},
    'GFDL-CM3'   =>
        $use_group{'GFDL-CM3_historical'} && $use_group{'GFDL-CM3_rcp85'}
);
my @valid_pairs = grep {$pairs{$_}} keys %pairs;
unless (@valid_pairs) {
    print STDERR "\033[31;1mERROR:\033[0m No valid sets of data groups were".
        " specified for the remaining steps.\n";
    exit 1;
}

for my $group (@valid_pairs) {
    print "\033[1m>>> $group <<<\033[0m\n";
    #
    # Deltas
    #
    if ($do_steps{'deltas'}) {
        print "Step: \033[1mDeltas\033[0m...\n";

        unless ($dry_run) {
            check_input_dir("output_interval_durations");
            create_output_dir("deltas");
        }

        my @command = (
            "$python_exec", "$script_dir/compute_deltas.py",
            '-p', "$data_dir/output_interval_durations/",
            '-o', "$data_dir/deltas/",
            '-d', "$group"
        );
        unshift(@command, 'srun') if ($in_slurm);

        do_command(@command)
    }

    #
    # Warp
    #
    if ($do_steps{'warp'}) {
        print "Step: \033[1mWarp\033[0m...\n";

        unless ($dry_run) {
            check_input_dir("deltas");
            check_input_dir("NOAA");
            create_output_dir("warped");
        }

        my @command = (
            "$python_exec", "$script_dir/warp_grid.py",
            '-p', "$data_dir/deltas/",
            '-a', "$data_dir/NOAA/",
            '-o', "$data_dir/warped/",
            '-d', "$group"
        );
        unshift(@command, 'srun') if ($in_slurm);

        do_command(@command)
    }

    #
    # Multiply
    #
    if ($do_steps{'multiply'}) {
        print "Step: \033[1mMultiply\033[0m...\n";

        unless ($dry_run) {
            check_input_dir("warped");
            check_input_dir("NOAA");
            create_output_dir("combined");
        }

        my @command = (
            "$python_exec", "$script_dir/multiply.py",
            '-p', "$data_dir/warped/",
            '-a', "$data_dir/NOAA/",
            '-o', "$data_dir/combined/",
            '-d', "$group"
        );
        unshift(@command, 'srun') if ($in_slurm);

        do_command(@command)
    }
}

#######################
# Helper functions
#######################

use List::Util qw(first);
use File::Path qw(make_path);

=for comment
Get the order index of the specified step
(or die if the name doesn't match anything)
=cut
sub get_order {
    my $step = shift @_;
    my $idx = first { $order[$_] eq $step } 0..$#order;
    die "Invalid step name '$step'." unless (defined($idx));
    return $idx;
}

=for comment
Parser for DATA_GROUPS option.
Parses comma-separated list of group names and dies if it reaches
an invalid name.
=cut
sub parse_data_groups {
    my $val = $_[1];

    return if ($val eq 'all');  # all is the default already, so do nothing
                                # if 'all' was specified.

    # Otherwise, assume all groups are false and just add the ones
    # that the user specified.
    $use_group{$_} = 0 foreach (keys %use_group);
    foreach my $name (split /,/, $val) {
        my @matches = grep m/$name/, @allowed_data_groups
            or die "'$name' did not match any data groups.";
        # Alert the user if a specified name matched more than one group
        # (in case it was accidental)
        if (@matches > 1) {
            print STDERR "\033[36;1mINFO:\033[0m Pattern '$name' matched".
                " multiple groups: " . join(', ', @matches) . "\n";
        }
        foreach my $group (@matches) {
            $use_group{$group} = 1;
        }
    }
}

=for comment
Parse for STEPS option.
Parses a list of ranges (using the same syntax as the cut command) for
the steps and dies if it reaches an invalid step name or invalid syntax.
=cut
sub parse_steps {
    my $val = $_[1];

    return if ($val eq 'all');  # all is the default already, so do nothing
                                # if 'all' was specified.

    # Otherwise, assume all steps are false and just add the ones
    # that the user specified.
    $do_steps{$_} = 0 foreach (keys %do_steps);
    foreach (split /,/, $val) {
        # For each segment the user specified, determine the appropriate slice
        # of the step ordering and set those steps to true.
        my @slice;
        if      (/^\w+$/)           { @slice = get_order($_);               }
        elsif   (/^-(\w+)$/)        { @slice = 0..get_order($1);            }
        elsif   (/^(\w+)-$/)        { @slice = get_order($1)..$#order;      }
        elsif   (/^(\w+)-(\w+)$/)   { @slice = get_order($1)..get_order($2);}
        else { die "Invalid list syntax."; }

        $do_steps{$_} = 1 foreach (@order[@slice]);
    }
}

=for comment
Check that a directory in the data directory exists.
Die if it does not
=cut
sub check_input_dir {
    my $dir = shift;
    unless (-d "$data_dir/$dir") {
        print STDERR "\033[31;1mERROR:\033[0m Directory '$dir' does not exist in data directory.\n";
        exit 1;
    }
}

=for comment
Create a directory in the data directory.
Die if unsuccessful
=cut
sub create_output_dir {
    my $dir = shift;
    make_path("$data_dir/$dir", {error => \my $err});
    if ($err && @$err) {
        print STDERR "\033[31;1mERROR:\033[0m Unable to create directory '$dir' in data directory.\n";
        exit 1;
    }
}

=for comment
Execute a command with 'system' (unless in dry-run mode, in which case print it).
Die if command fails
=cut
sub do_command {
    if ($dry_run) {
        print "\033[3;36m@_\033[0m\n";
    } else {
        system @_;
        if ( ($? >> 8) != 0) {
            print STDERR "\033[31;1mERROR:\033[0m Error occured executing step! Aborting...\n";
            exit 2;
        }
    }
}