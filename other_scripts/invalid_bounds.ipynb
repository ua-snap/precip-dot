{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invalid confidence interval diagnosis\n",
    "\n",
    "The purpose of this notebook is to aid in diagnosing the cause of invalid bounds on the confidence intervals for some precipitation estimates. \n",
    "\n",
    "**The issue**: lower bound $\\geq$ upper bound\n",
    "\n",
    "## example\n",
    "\n",
    "An example of this issue can be seen in the bounds for the **4d duration**, **1000yr interval** for **2020-2049 GFDL-CM3** output at latitude **67.61** and longitude **-156.75**, or X-coordinate of -117682.86362522288 and Y-coordinate of 1963676.5978819495 in EPSG:3338. The **estimate is 4.74**, with a **lower bound of 7.81** and an **upper bound of 2.68**.\n",
    "\n",
    "## where: deltas or warping?\n",
    "\n",
    "Does this problem appear to be present before or after the warping step? \n",
    "\n",
    "Since the confidence bounds are stored as the ratios between future bounds and historical bounds, it's not necessarily  incorrect if an upper bound delta is less than a lower bound delta. The issue is only present after the delta has been applied (multiplied). \n",
    "\n",
    "### testing\n",
    "1. a preliminary step in testing this is to just check that the deltas make sense using the data from the underlying delta calculation: the historical and future WRF precip estimates from the \"intervals\" step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/UA/kmredilla/.localpython/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "from pyproj import Transformer\n",
    "\n",
    "# directories\n",
    "data_dir = \"/workspace/Shared/Tech_Projects/DOT/project_data\"\n",
    "wrf_dir = os.path.join(data_dir, \"wrf_pcpt\")\n",
    "\n",
    "# WGS84 coordinates from example of invalid bounds\n",
    "wgs84_coords = (-156.75, 67.61)\n",
    "# WRF CRS\n",
    "wrf_crs = '+units=m +proj=stere +lat_ts=64.0 +lon_0=-152.0 +lat_0=90.0 +x_0=0 +y_0=0 +a=6370000 +b=6370000'\n",
    "transformer = Transformer.from_proj(\"EPSG:4326\", wrf_crs, always_xy=True)\n",
    "wrf_coords = transformer.transform(*wgs84_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open deltas, historical, and future\n",
    "deltas_ds = xr.open_dataset(os.path.join(wrf_dir, \"deltas\", \"pcpt_GFDL-CM3_sum_wrf_4d_2020-2049_deltas.nc\"))\n",
    "hist_ds = xr.open_dataset(os.path.join(wrf_dir, \"output_interval_durations\", \"pcpt_GFDL-CM3_historical_sum_wrf_4d_1979-2015_intervals.nc\"))\n",
    "future_ds = xr.open_dataset(os.path.join(wrf_dir, \"output_interval_durations\", \"pcpt_GFDL-CM3_rcp85_sum_wrf_4d_2020-2049_intervals.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query datasets at point\n",
    "deltas_sel = deltas_ds.sel(xc=wrf_coords[0], yc=wrf_coords[1], method=\"nearest\")\n",
    "hist_sel = hist_ds.sel(xc=wrf_coords[0], yc=wrf_coords[1], method=\"nearest\")\n",
    "future_sel = future_ds.sel(xc=wrf_coords[0], yc=wrf_coords[1], method=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for equality between $historical * deltas$ product and future values, with precision of 5 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all upper bounds equal: True\n",
      "all pf estimates equal: True\n",
      "all lower bounds equal: True\n"
     ]
    }
   ],
   "source": [
    "# function to compare equality of all values at five decimal places\n",
    "def arrs_equal(a1, a2):\n",
    "    return all(np.round(a1, 5) == np.round(a2, 5))\n",
    "\n",
    "# test multiplication against future\n",
    "du, dpf, dl = deltas_sel[\"pf-upper\"].values, deltas_sel[\"pf\"].values, deltas_sel[\"pf-lower\"].values\n",
    "hu, hpf, hl = hist_sel[\"pf-upper\"].values, hist_sel[\"pf\"].values, hist_sel[\"pf-lower\"].values\n",
    "fu, fpf, fl = future_sel[\"pf-upper\"].values, future_sel[\"pf\"].values, future_sel[\"pf-lower\"].values\n",
    "upper_equal = arrs_equal(du * hu, fu)\n",
    "pf_equal = arrs_equal(dpf * hpf, fpf)\n",
    "lower_equal = arrs_equal(dl * hl, fl)\n",
    "\n",
    "print(\"all upper bounds equal:\", upper_equal)\n",
    "print(\"all pf estimates equal:\", pf_equal)\n",
    "print(\"all lower bounds equal:\", lower_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the deltas for the exmaple problem appear valid, in the sense that multiplying them by the historical values gives the future values. \n",
    "\n",
    "Inspection of the historical and future estimates partly illuminates the underlying issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical upper bound: 32.664143 | Future upper bound: 11.907405\n",
      "Historical estimate: 9.411026 | Future estimate: 5.703586\n",
      "Historical lower bound: 3.1065607 | Future lower bound: 3.2861311\n"
     ]
    }
   ],
   "source": [
    "# indexing -1 for 1000yr RI\n",
    "i = -1\n",
    "print(\"Historical upper bound:\", hu[i], \"| Future upper bound:\", fu[i])\n",
    "print(\"Historical estimate:\", hpf[i], \"| Future estimate:\", fpf[i])\n",
    "print(\"Historical lower bound:\", hl[i], \"| Future lower bound:\", fl[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertatinty dencreases drastically from the historical period to the future period. Knowing this may be useful for informing a different method of quantifying uncertainty with the delta method, because it is evidence of the possibility that changes in the confidence bounds do not necessarily occur in the same direction as change in the pf estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, applying these deltas to the values of the corresponding Atlas 14 grid cell will confirm that the issue was present before warping, if that is indeed the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open rasters\n",
    "a14_upper = rio.open(os.path.join(data_dir, \"NOAA_Atlas14\", \"raw\", \"warped\", \"ak1000yr04dau_ams.tif\"))\n",
    "a14_pf = rio.open(os.path.join(data_dir, \"NOAA_Atlas14\", \"raw\", \"warped\", \"ak1000yr04da_ams.tif\"))\n",
    "a14_lower = rio.open(os.path.join(data_dir, \"NOAA_Atlas14\", \"raw\", \"warped\", \"ak1000yr04dal_ams.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get row/column of WGS84 example coordinates\n",
    "# transform to 3338\n",
    "transformer = Transformer.from_crs(4326, 3338, always_xy=True)\n",
    "a14_coords = transformer.transform(*wgs84_coords)\n",
    "a14_rc = a14_pf.index(*a14_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get combined values\n",
    "# define window for reading only the exact row, col\n",
    "window = ((a14_rc[0], a14_rc[0] + 1), (a14_rc[1], a14_rc[1] + 1))\n",
    "# read a14 values\n",
    "ub = a14_upper.read(1, window=window) / 1000\n",
    "pf = a14_pf.read(1, window=window) / 1000\n",
    "lb = a14_lower.read(1, window=window) / 1000\n",
    "# combined with deltas\n",
    "ub_c = np.round(ub * du[i], 3)\n",
    "pf_c = np.round(pf * dpf[i], 3)\n",
    "lb_c = np.round(lb * dl[i], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlas 14 lower bound, pf estimate, and upper bound: [[7.239]] [[9.843]] [[13.542]]\n",
      "Corresponding WRF-derived deltas:  1.058 0.606 0.365\n",
      "Combined values: [[7.657]] [[5.965]] [[4.937]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Atlas 14 lower bound, pf estimate, and upper bound:\", lb, pf, ub)\n",
    "print(\"Corresponding WRF-derived deltas: \", round(dl[i], 3), round(dpf[i], 3), round(du[i], 3))\n",
    "print(\"Combined values:\", lb_c, pf_c, ub_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that the problem is present after deltas step.\n",
    "\n",
    "## Possible solutions\n",
    "\n",
    "### 1. compute deltas from pf estimate - confidence bound differences\n",
    "\n",
    "One possible method is to save the deltas for the confidence bounds as ratios between differences from the pf estimate. Would that return valid estimates in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined values, possible solution 1: [[2.776]] [[5.965]] [[3.613]]\n"
     ]
    }
   ],
   "source": [
    "# new deltas for upper and lower bounds\n",
    "hu_1, fu_1 = hpf[i] - hu[i], fpf[i] - fu[i]\n",
    "hl_1, fl_1 = hpf[i] - hl[i], fpf[i] - fl[i]\n",
    "du_1 = fu_1 / hu_1\n",
    "dl_1 = fl_1 / hl_1\n",
    "# multiply\n",
    "ub_1 = np.round(ub * du_1, 3)\n",
    "lb_1 = np.round(lb * dl_1, 3)\n",
    "\n",
    "print(\"Combined values, possible solution 1:\", lb_1, pf_c, ub_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FAILS**\n",
    "\n",
    "This method does not gaurantee sensible confidence bounds; the resulting confidence bounds are still at the mercy of drastic changes in uncertainty between historical and future period.\n",
    "\n",
    "### 2. to be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
