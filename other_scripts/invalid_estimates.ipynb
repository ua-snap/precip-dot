{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invalid estimate diagnosis\n",
    "\n",
    "The purpose of this notebook is to aid in diagnosing the cause of invalid precipitation estimates in the combined (final) data.\n",
    "\n",
    "**expected**: for any duration $i$ and return interval $j$, the precipitation estimate at either $i,j + 1$ or $i + 1, j$ should be greater than the precipitation estimate at $i,j$. I.e., there should be a monotonic increasing relationship between precipitation estimate and both duration and return interval.\n",
    "\n",
    "**issue**: This is not the case. Precipitation stimates for arbitrary durations and return intervals are less than estimates for the next largest duration at same return interval. Have not yet seen issue within a duration and increasing return interals however, appears to be limited to fixed return interval.  \n",
    "\n",
    "## example\n",
    "\n",
    "An example of this issue can be seen in the bounds for the **7d duration**, **1000yr interval** for **2020-2049 GFDL-CM3** output at latitude **64.66** and longitude **-147.96**. The **estimate is 18.87**, and the estimate for the **4d duration** in the **same (1000yr) return interval** is 22.5. \n",
    "\n",
    "## where: deltas or warping?\n",
    "\n",
    "Does this problem appear to be present before or after the warping step? \n",
    "\n",
    "### testing\n",
    "1. verify that applying the unwarped deltas to the Atlas 14 values for this particular location recreates the invalid estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/UA/kmredilla/.localpython/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import os, time\n",
    "import lmoments3 as lmom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import scikits.bootstrap as boot\n",
    "import xarray as xr\n",
    "from lmoments3 import distr\n",
    "from multiprocessing import Pool\n",
    "from pyproj import Transformer\n",
    "\n",
    "# directories\n",
    "data_dir = \"/workspace/Shared/Tech_Projects/DOT/project_data\"\n",
    "wrf_dir = os.path.join(data_dir, \"wrf_pcpt\")\n",
    "\n",
    "# WGS84 coordinates from example of invalid bounds\n",
    "wgs84_coords = (-147.96, 64.66)\n",
    "# WRF CRS\n",
    "wrf_crs = '+units=m +proj=stere +lat_ts=64.0 +lon_0=-152.0 +lat_0=90.0 +x_0=0 +y_0=0 +a=6370000 +b=6370000'\n",
    "transformer = Transformer.from_proj(\"EPSG:4326\", wrf_crs, always_xy=True)\n",
    "wrf_coords = transformer.transform(*wgs84_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to query 1000yr delta at transformed coordinates\n",
    "def get_delta(fp, wrf_coords=wrf_coords):\n",
    "    deltas_ds = xr.open_dataset(fp)\n",
    "    deltas_sel = deltas_ds.sel(xc=wrf_coords[0], yc=wrf_coords[1], method=\"nearest\")\n",
    "    return deltas_sel[\"pf\"].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_fp = os.path.join(wrf_dir, \"deltas\", \"pcpt_GFDL-CM3_sum_wrf_{}d_2020-2049_deltas.nc\")\n",
    "deltas = {\n",
    "    \"4d\": get_delta(deltas_fp.format(\"4\")),\n",
    "    \"7d\": get_delta(deltas_fp.format(\"7\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get row/col for a14 grid, define window for rasters\n",
    "transformer = Transformer.from_crs(4326, 3338, always_xy=True)\n",
    "a14_coords = transformer.transform(*wgs84_coords)\n",
    "a14_pf = rio.open(os.path.join(data_dir, \"NOAA_Atlas14\", \"raw\", \"warped\", \"ak1000yr04da_ams.tif\"))\n",
    "a14_rc = a14_pf.index(*a14_coords)\n",
    "window = ((a14_rc[0], a14_rc[0] + 1), (a14_rc[1], a14_rc[1] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to query Atlas 14 estimates for each duration in example\n",
    "def get_a14_pf(fp, window=window):\n",
    "    a14_src = rio.open(fp)\n",
    "    return a14_src.read(1, window=window)[0][0] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a14_fp = os.path.join(data_dir, \"NOAA_Atlas14\", \"raw\", \"warped\", \"ak1000yr0{}da_ams.tif\")\n",
    "estimates = {\n",
    "    \"4d\": get_a14_pf(a14_fp.format(\"4\")),\n",
    "    \"7d\": get_a14_pf(a14_fp.format(\"7\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for invalid estimates after multiplying deltas with estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4d combined estimate: 25.541\n",
      "7d combined estimate: 16.876\n"
     ]
    }
   ],
   "source": [
    "print(\"4d combined estimate:\", round(estimates[\"4d\"] * deltas[\"4d\"], 3))\n",
    "print(\"7d combined estimate:\", round(estimates[\"7d\"] * deltas[\"7d\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that the problem is present after the deltas step. \n",
    "\n",
    "## Possible solutions\n",
    "\n",
    "### 1. rolling window method for durations step\n",
    "\n",
    "This method was causing some computational issues when initially tested on entire dataset. The goal here will be to explore this possibility using the data for only the example location, and check whether the issue was rectified.\n",
    "\n",
    "1. Load the historical and future data for the point-of-interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get xc, yc indices for the WRF coordinates\n",
    "wrf_fp = os.path.join(wrf_dir, \"pcpt\", \"pcpt_hourly_wrf_{}_{}_{}.nc\")\n",
    "pcpt_ds = xr.open_dataset(wrf_fp.format(\"GFDL-CM3\", \"historical\", \"1970\"))\n",
    "xc = pcpt_ds.xc.values\n",
    "yc = pcpt_ds.yc.values\n",
    "idx = (np.abs(xc - wrf_coords[0]).argmin(), np.abs(yc - wrf_coords[1]).argmin())\n",
    "pcpt_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to query a WRF pcpt dataset for all times\n",
    "def get_wrf_pcpt(fp, xc_idx=idx[0], yc_idx=idx[1]):\n",
    "    ds = xr.open_dataset(fp)\n",
    "    time = ds.time.values\n",
    "    pcpt = ds[\"pcpt\"].values[:,yc_idx,xc_idx]\n",
    "    ds.close()\n",
    "    da = xr.DataArray(pcpt, coords=[time], dims=[\"time\"])\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.6 s\n"
     ]
    }
   ],
   "source": [
    "# read historical data\n",
    "tic = time.perf_counter()\n",
    "\n",
    "years = np.arange(1970, 2006).astype(\"str\")\n",
    "wrf_fps = [wrf_fp.format(\"GFDL-CM3\", \"historical\", year) for year in years]\n",
    "p = Pool(24)\n",
    "hist_da_list = p.map(get_wrf_pcpt, wrf_fps)\n",
    "p.close()\n",
    "\n",
    "print(round(time.perf_counter() - tic, 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.7 s\n"
     ]
    }
   ],
   "source": [
    "# read future data\n",
    "tic = time.perf_counter()\n",
    "\n",
    "years = np.arange(2020, 2050).astype(\"str\")\n",
    "wrf_fps = [wrf_fp.format(\"GFDL-CM3\", \"rcp85\", year) for year in years]\n",
    "p = Pool(24)\n",
    "rcp85_da_list = p.map(get_wrf_pcpt, wrf_fps)\n",
    "p.close()\n",
    "\n",
    "print(round(time.perf_counter() - tic, 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat data arrays\n",
    "hist = xr.concat(hist_da_list, \"time\")\n",
    "rcp85 = xr.concat(rcp85_da_list, \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. calculate the durations series - sum the precip amounts over 4 day and 7 day periods, implementing both rolling and binning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to the respective durations\n",
    "def calc_dur(da):\n",
    "    dur_di = {\n",
    "        \"4d\": {\n",
    "            \"bin\": da.resample(time=\"4D\").sum(), \n",
    "            \"roll\": da.rolling(time=(4 * 24)).sum().dropna(\"time\")\n",
    "        },\n",
    "        \"7d\": {\n",
    "            \"bin\": da.resample(time=\"7D\").sum(), \n",
    "            \"roll\": da.rolling(time=(7 * 24)).sum().dropna(\"time\")\n",
    "        },\n",
    "    }\n",
    "    return dur_di\n",
    "\n",
    "hist_dur = calc_dur(hist)\n",
    "rcp85_dur = calc_dur(rcp85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify that the calculated durations series match the durations series computed from the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of precip sums from pipeline: [ 3.782     12.1015     5.26      17.661499   0.9404998]\n",
      "Sample of precip sums calculated from raw WRF: [ 3.278      7.8299994 10.0355     6.111     11.969    ]\n"
     ]
    }
   ],
   "source": [
    "# open durations file, query at POI\n",
    "def get_dur(fp, xc=wrf_coords[0], yc=wrf_coords[1]):\n",
    "    dur_ds = xr.open_dataset(fp)\n",
    "    return dur_ds.sel(xc=xc, yc=yc, method=\"nearest\").pcpt\n",
    "\n",
    "dur_fp = os.path.join(wrf_dir, \"durations\", \"pcpt_{}_sum_wrf_{}_{}.nc\")\n",
    "pipe_dur = {\n",
    "    \"4d\": {\n",
    "        \"hist\": get_dur(dur_fp.format(\"4d\", \"GFDL-CM3\", \"historical\")), \n",
    "        \"rcp85\": get_dur(dur_fp.format(\"4d\", \"GFDL-CM3\", \"rcp85\"))\n",
    "    }, \n",
    "    \"7d\": {\n",
    "        \"hist\": get_dur(dur_fp.format(\"7d\", \"GFDL-CM3\", \"historical\")), \n",
    "        \"rcp85\": get_dur(dur_fp.format(\"7d\", \"GFDL-CM3\", \"rcp85\"))\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Sample of precip sums from pipeline:\", pipe_dur[\"4d\"][\"hist\"].values[:5])\n",
    "print(\"Sample of precip sums calculated from raw WRF:\", hist_dur[\"4d\"][\"bin\"].values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They don't match. This warrants further investigation.\n",
    "\n",
    "However, this mthod can still be tested with the manually computed durations series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate annual maximum series using both rolling and original methods (for both sets of durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return ditcionary of ams from dict of durations\n",
    "def run_calc_ams(dur_di, yr_sl=(\"1979\", \"2015\")):\n",
    "    def calc_ams(di):\n",
    "        return {k: da.sel(time=slice(yr_sl[0], yr_sl[1])).resample(time=\"Y\").max() for k, da in di.items()}\n",
    "    return {k: calc_ams(sub_di) for k, sub_di in dur_di.items()}\n",
    "\n",
    "hist_ams = run_calc_ams(hist_dur)\n",
    "rcp85_ams = run_calc_ams(rcp85_dur, (\"2020\", \"2049\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. calculate deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_values(dat):\n",
    "    paras = distr.gev.lmom_fit(dat)\n",
    "    return distr.gev(**paras)\n",
    "\n",
    "# compute deltas from global dicts\n",
    "def calc_delta(hist, rcp85):\n",
    "    p = 1 - 1/1000\n",
    "    hist_fit = fit_values(hist)\n",
    "    rcp_fit = fit_values(rcp85)\n",
    "    return round(rcp_fit.ppf(p) / hist_fit.ppf(p), 3)\n",
    "\n",
    "def run_calc_delta(dur, sub_di):\n",
    "    return {k: calc_delta(da.values, rcp85_ams[dur][k]) for k, da in sub_di.items()}\n",
    "\n",
    "deltas_di = {k: run_calc_delta(k, sub_di) for k, sub_di in hist_ams.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4d': {'bin': 4.587, 'roll': 4.708}, '7d': {'bin': 5.045, 'roll': 3.559}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas_di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4d delta actually increases, whereas the 7d delta decreases. This would result in a greater inconsistency. \n",
    "\n",
    "This rules out the rolling window method for the durations step as a potential solution. \n",
    "\n",
    "Curious about whether the ordering in the output intervals step is preserved, however.\n",
    "\n",
    "Here are the historical estimates based on durations method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1 - 1/1000\n",
    "colnames = [\"Binning\", \"Rolling\"]\n",
    "methods = [\"bin\", \"roll\"]\n",
    "\n",
    "def get_df(ams_di):\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\n",
    "            k: [\n",
    "                round(fit_values(sub_di[method]).ppf(p), 2) for method, da in sub_di.items()\n",
    "            ] for k, sub_di in ams_di.items()\n",
    "        },\n",
    "        orient=\"index\", columns=colnames\n",
    "    )\n",
    "    \n",
    "\n",
    "hist_pf = get_df(hist_ams)\n",
    "rcp85_pf = get_df(rcp85_ams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binning</th>\n",
       "      <th>Rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4d</th>\n",
       "      <td>73.54</td>\n",
       "      <td>66.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d</th>\n",
       "      <td>71.61</td>\n",
       "      <td>101.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Binning  Rolling\n",
       "4d    73.54    66.09\n",
       "7d    71.61   101.86"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the future estimates for each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binning</th>\n",
       "      <th>Rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4d</th>\n",
       "      <td>337.35</td>\n",
       "      <td>311.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d</th>\n",
       "      <td>361.30</td>\n",
       "      <td>362.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Binning  Rolling\n",
       "4d   337.35   311.14\n",
       "7d   361.30   362.56"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcp85_pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the resulting deltas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binning</th>\n",
       "      <th>Rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4d</th>\n",
       "      <td>4.59</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d</th>\n",
       "      <td>5.05</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Binning  Rolling\n",
       "4d     4.59     4.71\n",
       "7d     5.05     3.56"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas_df = np.round(rcp85_pf / hist_pf, 2)\n",
    "deltas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying each of these by the corresponding 4d and 7d Atlas 14 1000yr estimates of 7.18 and 8.18, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a14_lu = {\"4d\": 7.18, \"7d\": 8.18}\n",
    "combined = deltas_df.copy()\n",
    "for idx in deltas_df.index.values:\n",
    "    combined.loc[idx] = np.round(deltas_df.loc[idx] * a14_lu[idx], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binning</th>\n",
       "      <th>Rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4d</th>\n",
       "      <td>32.96</td>\n",
       "      <td>33.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d</th>\n",
       "      <td>41.31</td>\n",
       "      <td>29.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Binning  Rolling\n",
       "4d    32.96    33.82\n",
       "7d    41.31    29.12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
