{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `precip-dot` data test `04`:\n",
    "## Sane values in final data\n",
    "\n",
    "Verify that estimates in the final data are sane. This means no negative estimates or confidence bounds.\n",
    "\n",
    "### inputs\n",
    "\n",
    "The path to the directory containing the \"combined\" data to test needs to be specified in the `UNDIFF_DIR` env var prior to running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(fp):\n",
    "    \"\"\"\n",
    "    sanity check all data in a final output file\n",
    "    \"\"\"\n",
    "    def sane_values(arr):\n",
    "        arr = arr.flatten()\n",
    "        return arr[~np.isnan(arr)] >= 0\n",
    "    vars = [\"pf\", \"pf_lower\", \"pf_upper\"]\n",
    "    with xr.open_dataset(fp) as ds:\n",
    "        results = [np.all(sane_values(ds[var].values)) for var in vars]\n",
    "    return (fp, results)\n",
    "   \n",
    "    \n",
    "def run_test(data_dir):\n",
    "    \"\"\"\n",
    "    run test on output data directory\n",
    "    \"\"\"\n",
    "    print(\"Beginning test of consistent estimates in final data.\\n\")\n",
    "\n",
    "    # check on all data files\n",
    "    fps = glob.glob(os.path.join(data_dir, \"*.nc\"))\n",
    "\n",
    "    p = Pool(20)\n",
    "    results = p.map(sanity_check, fps)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    test_result = np.all([result[1] for result in results])\n",
    "    # print results\n",
    "    if test_result:\n",
    "        print(\"\\nTest result: PASS\")\n",
    "    else:\n",
    "        print(\"\\nTest result: FAIL\\n\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning test of consistent estimates in final data.\n",
      "\n",
      "\n",
      "Test result: FAIL\n",
      "\n",
      "Elapsed time: 7.3 m\n",
      "\n",
      "Completion time of previous test: 2020-11-11 03:19:59\n"
     ]
    }
   ],
   "source": [
    "import os, time, datetime, glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from multiprocessing import Pool\n",
    "\n",
    "data_dir = os.getenv(\"UNDIFF_DIR\")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "_ = run_test(data_dir)\n",
    "\n",
    "print(\"Elapsed time: {} m\\n\".format(round((time.perf_counter() - tic) / 60, 1)))\n",
    "\n",
    "utc_time = datetime.datetime.utcnow()\n",
    "print(\"Completion time of previous test: {}\".format(utc_time.strftime(\"%Y-%m-%d %H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Shared/Tech_Projects/DOT/project_data/wrf_pcpt/undiff/pcpt_GFDL-CM3_sum_wrf_10d_2020-2049_undiff.nc'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sane_values(arr):\n",
    "    arr = arr.flatten()\n",
    "    return np.all(arr[~np.isnan(arr)] >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\"pf\", \"pf_lower\", \"pf_upper\"]\n",
    "with xr.open_dataset(fp) as ds:\n",
    "    results = [np.all(sane_values(ds[var].values)) for var in vars]\n",
    "#return (fp, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"/workspace/Shared/Tech_Projects/DOT/project_data/wrf_pcpt/undiff/pcpt_GFDL-CM3_sum_wrf_10d_2020-2049_undiff.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# On branch data_tests\r\n",
      "# Untracked files:\r\n",
      "#   (use \"git add <file>...\" to include in what will be committed)\r\n",
      "#\r\n",
      "#\tother_scripts/durations_with_test_print.py\r\n",
      "#\tother_scripts/read_test_output.py\r\n",
      "#\tother_scripts/test_toy_durations.py\r\n",
      "#\tother_scripts/test_toy_durations_mimic.py\r\n",
      "#\tother_scripts/tests/sanity_check.ipynb\r\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
