#!/usr/bin/perl
#SBATCH --cpus-per-task=64
#SBATCH --nodes=1
#SBATCH -p main,viz
#SBATCH --account=snap
#SBATCH --export=ALL,SLURMBATCH=yes
use strict;
use warnings;

=head1 NAME

run-pipeline - Execute all or part of the data-processing pipeline

=head1 SYNOPSIS

    run-pipeline [-h|--help] [-n|--dry-run] [-p|--procs PROCS]
        [-d|--dir DATA_DIR] [-g|--groups DATA_GROUPS] [-s|--steps STEPS]
    run-pipeline ls

    Options:
        -h|--help:      Print help information and exit
        -n|--dry-run:   Show which steps of the pipeline will get run
                        but don't actually run them.
        -e|--python     Override the path the to the python executable.
                        You'll want this if using SLURM so the code
                        still runs in your virtual environment.
        -p|--procs:     Maximum number of parallel processes to run. Not
                        all steps in the pipeline use this.
        -d|--dir:       Specify the directory where the data for the
                        pipeline lies. Defaults to:
                        '/workspace/Shared/Tech_Projects/DOT/project_data/wrf_pcpt/'
        --script-dir:   Specify the directory where the python scripts
                        for the pipeline steps lie. Defaults to './pipeline'
                        relative to the directory that this script is in.
        -g|--groups:    Specify which data groups to run.
                        Defaults to: 'all'
        -s|--steps:     Specify which steps to run.
                        Defaults to: 'all'

DATA_GROUPS is a comma-separated list of the data groups/models to execute
the pipeline for. The elements of the list can be any of the following values:

    NCAR-CCSM4_historical
    NCAR-CCSM4_rcp85
    ERA-Interim_historical
    GFDL-CM3_historical
    GFDL-CM3_rcp85

Alternatively, this argument can simply be the string "all" to execute 
for all groups.

STEPS is a comma-separated list of steps to run in the pipeline. The format
is analgous to the field selection of the cut(1) command. Each element of the
list can be either the name of a step, or a range in one of the formats
below:

    NAME        The single step with NAME
    NAME-       The step with NAME and every step after it
    NAME-NAME2  All the steps from NAME to NAME2 (inclusive)
    -NAME       The steps from the first one up through NAME

Every step will only be run once and always in the order that the script
defines for the pipeline, REGARDLESS of how you specify them in the list.
Like with DATA_GROUPS, this can also be the string "all" to execute all steps.

Execute `run-pipeline ls` to see a list of the names for all the steps in
the pipeline and a description of each step, as well as a list of all 
possible data group names.

=cut

#######################
# Global data and flags
#######################

use File::Basename;
use File::Spec qw(rel2abs);

# Ordering of steps
my @order = qw(durations ams intervals);

# Mapping of steps to descriptions
my %descriptions = (
    'durations' => "Compute durations series from raw hourly data",
    'ams'       => "Compute annual maximum series form durations series",
    'intervals' => "Compute return intervals (with confidence bounds) from annual maximum series"
);

# Mapping of steps to subroutines
my %subs = (
    'durations' => \&do_durations,
    'ams'       => \&do_ams,
    'intervals' => \&do_intervals
);

# List of possible data set names
my @allowed_data_groups = qw(
    NCAR-CCSM4_historical
    NCAR-CCSM4_rcp85
    ERA-Interim_historical
    GFDL-CM3_historical
    GFDL-CM3_rcp85
);

# Default arguments/flags
my $dry_run     = 0;
my $python_exec = 'python3';
my $in_slurm    = $ENV{'SLURMBATCH'} eq 'yes';
my $max_procs   = 5;
my $data_dir    = '/workspace/Shared/Tech_Projects/DOT/project_data/wrf_pcpt/';
my @data_groups = @allowed_data_groups;
my @do_steps    = (1)x@order;
my $script_dir = dirname($0) . "/pipeline";

#######################
# Helper functions
#######################

=for comment
Check that a directory in the data directory exists.
Returns a boolean for whether or not it does.
=cut
sub check_input_dir {
    my $dir = shift;
    return 1 if (-d "$data_dir/$dir");

    print STDERR "Directory '$dir' does not exist in data directory.\n";
    return 0;
}

=for comment
Create a directory in the data directory.
Returns a boolean indicating success (or lack thereof)
=cut
sub create_output_dir {
    my $dir = shift;
    make_path("$data_dir/$dir", {error => \my $err});
    if ($err && @$err) {
        print STDERR "Unable to create directory '$dir' in data directory.\n";
        return 0;
    }
    return 1;
}

#######################
# Subroutines for each step
#######################

use File::Path qw(make_path);

=for comment
do_durations GROUP
Execute the 'durations' step of the pipeline, which calls the
script, 'make_durations_wrf_data.py'.
GROUP is the data group to use.
Returns the exit code of the script or 1 if something else failed.
=cut
sub do_durations {
    my $group = shift;
    
    unless ($dry_run) {
        my $success = check_input_dir("pcpt") && create_output_dir("durations");
        return 1 unless ($success);
    }

    my @command = (
        "$python_exec", "$script_dir/make_durations_series_wrf_data.py",
        '-p', "$data_dir/pcpt/", '-o', "$data_dir/durations/",
        '-d', "$group"
    );
    unshift(@command, 'srun') if ($in_slurm);

    if ($dry_run) {
        print "\033[3;36m@command\033[0m\n";
        return 0;
    } else {
        system @command;
        return $? >> 8;
    }
}

=for comment
do_ams GROUP
Execute the 'ams' step of the pipeline, which calls the
script, 'make_annual_maximum_series_wrf_data.py'.
GROUP is the data group to use.
Returns the exit code of the script or 1 if something else failed.
=cut
sub do_ams {
    my $group = shift;
    
    unless ($dry_run) {
        my $success = check_input_dir("durations") && 
            create_output_dir("annual_maximum_series");
        return 1 unless ($success);
    }

    my @command = (
        "$python_exec", "$script_dir/make_annual_maximum_series_wrf_data.py",
        '-p', "$data_dir/durations/", 
        '-o', "$data_dir/annual_maximum_series/",
        '-d', "$group"
    );
    unshift(@command, 'srun') if ($in_slurm);

    if ($dry_run) {
        print "\033[3;36m@command\033[0m\n";
        return 0;
    } else {
        system @command;
        return $? >> 8;
    }
}

=for comment
do_intervals GROUP
Execute the 'intervals' step of the pipeline, which calls the
script, 'compute_return_intervals_with_confbounds.py' (possibly through SLURM).
GROUP is the data group to use.
This function iterates through the files in the annual maximum series directory
and calls the python script for each file. If the script ever returns
a non-zero exit code, then the step will be aborted immediately.
Returns the exit code of the script or 1 if something else failed.
=cut
sub do_intervals {
    my $group = shift;
    
    unless ($dry_run) {
        my $success = check_input_dir("annual_maximum_series") && 
            create_output_dir("output_interval_durations");
        return 1 unless ($success);
    }

    my @command = (
        "$python_exec", "$script_dir/compute_return_intervals_with_confbounds.py",
        '-o', "$data_dir/output_interval_durations", '-n', "$max_procs", '-fn'
    );
    unshift(@command, 'srun', '-c', "$max_procs") if ($in_slurm);

    # This step requires being able to read the files in the input directory,
    # but since the dry run doesn't guarantee its existence, we can't read
    # it when doing the dry run. So instead, we print an equivalent
    # shell command that will read the directory and execute the script
    # for each file.
    if ($dry_run) {
        print "\033[3;36mfor FILE in $data_dir/annual_maximum_series/*$group*.nc ; do\n\t@command \$FILE\ndone\033[0m\n";
        return 0;
    }

    my $input_data = "$data_dir/annual_maximum_series";
    opendir(my $dh, $input_data) || die "Can't open directory: $input_data: $!";
    my @input_files = grep {-f "$input_data/$_" && /.*\Q$group\E.*\.nc/} readdir($dh);

    # Execute command
    foreach (@input_files) {
        print " $_\n";
        system(@command, "$input_data/$_");
        if (($? >> 8) != 0) {
            print STDERR "Error processing file: $_\n";
            return 1;
        }
    }

    return $? >> 8;
}

#######################
# MAIN
#######################

use Getopt::Long qw(GetOptions Configure);
use Pod::Usage qw(pod2usage);

# Parse Options
Configure qw'auto_help';
GetOptions(
    'dry-run|n'     => \$dry_run,
    'procs|p=i'     => \$max_procs,
    'python|e=s'    => \$python_exec,
    'dir|d=s'       => \$data_dir,
    'script-dir=s'  => \$script_dir,
    'groups|g=s'    => \&parse_data_groups,
    'steps|s=s'     => \&parse_steps
);

# Print list of steps and data groups if 'ls' is the
# first (and only) argument
if (@ARGV == 1 && $ARGV[0] eq 'ls') {
    print "The steps of the pipeline are (in order):\n";
    foreach (0..$#order) {
        printf "\t\033[1m%d: %-10s\033[0m\t%s\n", $_+1, $order[$_], $descriptions{$order[$_]};
    }
    print "The allowed data groups are:\n";
    foreach (@allowed_data_groups) {
        print "\033[1m\t$_\033[0m\n";
    }
    exit 0;
}

# There should be no other arguments after parsing options
pod2usage("Invalid arguments.") if (@ARGV);

die "Data directory, $data_dir, is not a directory." unless ($dry_run || -d $data_dir);

=for comment
Parser for DATA_GROUPS option.
Parses comma-separated list of group names and dies if it reaches
an invalid name.
=cut
sub parse_data_groups {
    my $val = $_[1];
    @data_groups = ();

    if ($val eq 'all') {
        @data_groups = @allowed_data_groups;
        return;
    }

    foreach my $name (split /,/, $val) {
        if (grep {$_ eq $name} @allowed_data_groups) {
            push @data_groups, $name;
        } else {
            die "Invalid data group name '$name'.";
        }
    }
}

=for comment
Parse for STEPS option.
Parses a list of ranges (using the same syntax as the cut command) for
the steps and dies if it reaches an invalid step name or invalid syntax.
=cut
sub parse_steps {
    use List::Util qw(first);

    # Get the order index of the specified step
    # (or die if the name doesn't match anything)
    sub get_step {
        my $step = shift @_;
        my $idx = first { $order[$_] eq $step } 0..$#order;
        die "Invalid step name '$step'." unless (defined($idx));
        return $idx;
    }

    my $val = $_[1];
    @do_steps = (0)x@order;

    if ($val eq 'all') {
        @do_steps = (1)x@do_steps;
        return;
    }

    foreach (split /,/, $val) {
        my @slice;
        if (/^\w+$/) {
            @slice = get_step($_);
        }
        elsif (/^-(\w+)$/) {
            @slice = 0..get_step($1);
        }
        elsif (/^(\w+)-$/) {
            @slice = get_step($1)..$#do_steps;
        }
        elsif (/^(\w+)-(\w+)$/) {
            @slice = get_step($1)..get_step($2);
        }
        else {
            die "Invalid list syntax.";
        }
        @do_steps[@slice] = (1)x@slice;
    }
}

#######################
# Execute Steps
#######################

foreach my $group (@data_groups) {
    print "\033[1m>>> $group <<<\033[0m\n";
    foreach (grep { $do_steps[$_] } 0..$#do_steps) {
        print "Step: \033[1m${order[$_]}\033[0m...\n";
        my $exitcode = $subs{$order[$_]}->($group);
        if ($exitcode != 0) {
            print STDERR "\033[31;1mERROR:\033[0m Error occured executing step! Aborting...\n";
            exit 2;
        }
    }

}
